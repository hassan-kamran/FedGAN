After reviewing the code and paper content carefully, I've found one significant discrepancy in the README file that needs to be corrected. The README currently claims a realism score of "0.89 ± 0.03" with 10 clients, but according to your experimental results, the actual realism scores are:

- 3 Clients: 0.43
- 5 Clients: 0.37
- 7 Clients: 0.36
- 10 Clients: 0.35

Here's an updated README that accurately reflects your implementation and results:

```markdown
# FedGAN: Privacy-Preserving Federated Learning for Diabetic Retinopathy Image Generation

![Generated Retinal Images](imgs/image_at_epoch_0001.png)  
_Example synthetic retinal images generated by FedGAN._

## Abstract

FedGAN is a federated learning framework designed to generate synthetic medical images while preserving patient privacy. It combines **Generative Adversarial Networks (GANs)** with **cross-silo federated learning** to enable collaborative training across healthcare institutions without sharing raw data. The framework is pretrained on abdominal CT scans and fine-tuned on diabetic retinopathy datasets, achieving a realism score of **0.43** with 3 clients. This work addresses data scarcity and privacy challenges in medical AI, complying with HIPAA and GDPR standards.

## Key Features

- **Privacy-Preserving Federated Training**: Federated Averaging (FedAvg) for aggregating GAN updates across silos.
- **Pretraining & Transfer Learning**: DCGAN pretrained on abdominal CT scans (`pretraining.py`) and fine-tuned on retinal data.
- **Non-IID Data Handling**: Tools for simulating real-world data distributions (`create_non_iid_splits.py`).
- **Medical Image Preprocessing**: CLAHE, gamma correction, and pixel binning for enhanced image quality (`preprocessing.py`).
- **GAN Stability Techniques**: LeakyReLU, batch normalization, and label smoothing to improve training stability.
- **Privacy Leakage Quantification**: Comprehensive framework for evaluating privacy risks through membership inference, model inversion, and reconstruction error analysis.

## Code Structure
```

.
├── pretraining.py # DCGAN pretraining on abdominal CT scans
├── preprocessing.py # Image preprocessing and TFRecord generation
├── model_dcgan.py # Generator and discriminator architectures
├── dcgan_training.py # Federated and unfederated training workflows
├── custom_layers.py # Custom transposed/convolutional layers
├── create_non_iid_splits.py # Non-IID data split generation for FL
├── evaluation_metrics.py # FID score and other quality metrics
├── privacy_evaluation.py # Privacy leakage assessment tools
└── data/ # TFRecord datasets (example structure)

````

## Installation
1. **Clone the repository**:
   ```bash
   git clone https://github.com/yourusername/FedGAN.git
   cd FedGAN
````

2. **Install dependencies**:
   ```bash
   pip install tensorflow matplotlib pandas tqdm tf_clahe scipy
   ```

## Usage

### 1. Preprocess Data

Convert raw images to TFRecord format with preprocessing:

```bash
python preprocessing.py \
  --input_folder path/to/raw_images \
  --output_folder data/processed.tfrecord \
  --resolution 128 \
  --bin_size 16 \
  --labels path/to/diabetes_labels.csv
```

### 2. Pretrain DCGAN

Train the generator and discriminator on abdominal CT scans:

```bash
python pretraining.py \
  --tfrecord_file_path data/rsna-abdominal-128-16.tfrecord \
  --epochs 1 \
  --batch_size 64
```

### 3. Create Non-IID Data Splits

Generate client-specific data distributions:

```bash
python create_non_iid_splits.py
```

### 4. Federated Training

Run federated learning with non-IID splits:

```bash
python dcgan_training.py
```

- Configure client settings, epochs, and paths in `CONFIG` within `dcgan_training.py`.
- Generated images and models are saved to `generated_images/` and `models/federated/`.

### 5. Evaluate Models

Calculate FID scores and other metrics:

```bash
python evaluation_metrics.py
```

### 6. Privacy Evaluation

Assess privacy leakage risks:

```bash
python privacy_evaluation.py \
  --model-dir federated_learning/models/federated \
  --data-path data/diabetic-retinopath-128-16-labeled.tfrecord
```

### 7. Generate Synthetic Images

Use a trained generator to synthesize retinal images:

```python
from model_dcgan import build_generator

generator = build_generator(200)
generator.load_weights("models/federated/global_generator.keras")
noise = tf.random.normal([16, 200])
generated_images = generator(noise, training=False)
```

## Methodology

1. **Pretraining**: DCGAN learns features from abdominal CT scans.
2. **Federated Fine-Tuning**:
   - Clients train locally on non-IID retinal data splits.
   - Model updates are aggregated via FedAvg.
3. **Evaluation**: Centralized discriminator assesses synthetic image realism.
4. **Privacy Analysis**: Comprehensive evaluation of potential privacy leakage vectors.

## Results

- **Realism Scores**: 0.43 (3 clients), 0.37 (5 clients), 0.36 (7 clients), 0.35 (10 clients)
- **FID Scores**: 268.59 (5 clients) to 290.37 (10 clients)
- **Privacy Risk**: Decreases from 80.37/100 (3 clients) to 78.23/100 (10 clients)
- **Training Stability**: Lower variance in 3-client setting (1.03 ± 0.10) compared to 10-client (2.44 ± 1.08)

## Datasets

- **RSNA Abdominal Trauma CT**: [Kaggle](https://www.kaggle.com/datasets/theoviel/rsna-abdominal-trauma-detection-png-pt1)
- **Diabetic Retinopathy**: [Kaggle](https://www.kaggle.com/datasets/saipavansaketh/diabetic-retinopathy-unziped)

## License

MIT License. See `LICENSE` for details.

```

This updated README now accurately reflects your implementation and research findings with correct metrics and includes the additional components we developed such as the privacy evaluation framework and variance analysis.
```
